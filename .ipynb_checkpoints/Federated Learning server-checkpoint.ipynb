{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "fb85658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import struct\n",
    "import time\n",
    "import numpy as np\n",
    "from serial.tools.list_ports import comports\n",
    "\n",
    "def read_number(msg):\n",
    "    while True:\n",
    "        try:\n",
    "            #return 2;\n",
    "            return int(input(msg))\n",
    "        except: print(\"ERROR: Not a number\")\n",
    "\n",
    "def read_port(msg):\n",
    "    while True:\n",
    "        try:\n",
    "            port = input(msg)\n",
    "            #index = input(msg)\n",
    "            #port = \"COM8\";\n",
    "            return serial.Serial(port, 9600)\n",
    "        except: print(f\"ERROR: Wrong port connection\")\n",
    "            \n",
    "def print_until_keyword(keyword, device):\n",
    "    while True: \n",
    "        msg = device.serial.readline().decode()\n",
    "        if msg[:-2] == keyword: break\n",
    "        #else: print(f'({arduino.port}):',msg, end='')\n",
    "            \n",
    "def read_matrix(device, dimms):\n",
    "    result = np.zeros((1,dimms)).reshape(-1)\n",
    "    for i in range(dimms):\n",
    "        device.serial.read()\n",
    "        result[i] = struct.unpack('f', device.serial.read(4))[0]\n",
    "    \n",
    "    return result.reshape(dimms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "643480b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Device:\n",
    "    def __init__(self, serial):\n",
    "        self.serial = serial\n",
    "        self.weights = []\n",
    "        self.metalayers = []\n",
    "        \n",
    "    def set_weights(self, weights):\n",
    "        self.weights = weight\n",
    "        \n",
    "    def set_metadata(self, metalayer):\n",
    "        self.metalayer = metalayer\n",
    "        \n",
    "def getDevices():\n",
    "    num_devices = read_number(\"Number of devices: \")\n",
    "    # num_devices = 2\n",
    "\n",
    "    available_ports = comports()\n",
    "    print(\"Available ports:\")\n",
    "    for available_port in available_ports: print(available_port)\n",
    "\n",
    "    devices = [read_port(f\"Port device_{i+1}: \") for i in range(num_devices)]\n",
    "    list_devices = []\n",
    "    for device in devices:\n",
    "        list_devices.append(Device(device))\n",
    "    return list_devices\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, layer_type):\n",
    "        self.layer_type = layer_type\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"{self.layer_type}\"\n",
    "    \n",
    "class Dense(Layer):\n",
    "    def __init__(self, rows, cols):\n",
    "        super().__init__(\"Dense\")\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"{self.layer_type=} {self.rows=} {self.cols=}\"\n",
    "    \n",
    "class MaxPooling(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"MaxPooling\")\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"{self.layer_type}\"\n",
    "    \n",
    "class Conv2D(Layer):\n",
    "    def __init__(self, kh, kw, c, kc):\n",
    "        super().__init__(\"Conv2D\")\n",
    "        self.kh = kh\n",
    "        self.kw = kw\n",
    "        self.c = c\n",
    "        self.kc = kc\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"{self.layer_type=} - {self.kh=} {self.kw=} {self.c=} {self.kc=}\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "3aa60eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the blank model to all the devices\n",
    "def receive_model_info(device):\n",
    "    device.serial.reset_input_buffer()\n",
    "    device.serial.write(b's') # Python --> ACK --> Arduino\n",
    "    print_until_keyword('start', device) # CLEAN SERIAL\n",
    "    \n",
    "    bytesToRead = device.serial.read(1).decode()\n",
    "    time.sleep(1)\n",
    "    if bytesToRead == 'i':\n",
    "        [num_layers] = struct.unpack('i', device.serial.read(4))\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            [layer_type] = struct.unpack('i', device.serial.read(4))\n",
    "            if layer_type == -1:\n",
    "                [rows, cols] = struct.unpack('ii', device.serial.read(8))\n",
    "                layers.append(Dense(rows, cols))\n",
    "            elif layer_type == -2:\n",
    "                layers.append(MaxPooling())\n",
    "            elif layer_type == -3:\n",
    "                [kh, kw, c, kc] = struct.unpack('iiii', device.serial.read(16))\n",
    "                layers.append(Conv2D(kh,kw,c,kc))\n",
    "            # dimms.append((1,cols)) # bias\n",
    "            # dimms.append((rows,cols)) # matrix weigths\n",
    "    return num_layers, layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6d79225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_device_weights(device, bias_dimm, w_dimm):\n",
    "    bias = np.zeros(bias_dimm)\n",
    "    weights = np.random.randn(w_dimm[0], w_dimm[1]) * np.sqrt(6.0 / (w_dimm[0] + w_dimm[1]))\n",
    "    print(f\"Sending weights for Dense\")\n",
    "    for b in bias.reshape(-1):\n",
    "        data = device.serial.read()\n",
    "        device.serial.write(struct.pack('f', b))\n",
    "\n",
    "    for w in weights.reshape(-1):\n",
    "        data = device.serial.read()\n",
    "        device.serial.write(struct.pack('f', w))\n",
    "    \n",
    "def initialize_device_weights_cnn(device, kh, kw, c, kc):\n",
    "    bias = np.zeros((1,kc))\n",
    "    in_size = kh * kw * c\n",
    "    out_size = kh * kw * kc\n",
    "    weights = np.random.randn(kh, kw, c, kc) * np.sqrt(6.0 / (in_size + out_size))\n",
    "    print(f\"Sending weights for layer Conv2D\")\n",
    "    for b in bias.reshape(-1):\n",
    "        data = device.serial.read()\n",
    "        device.serial.write(struct.pack('f', b))\n",
    "\n",
    "    for w in weights.reshape(-1):\n",
    "        data = device.serial.read()\n",
    "        device.serial.write(struct.pack('f', w))\n",
    "    \n",
    "## RECEIVE MODEL WEIGHT\n",
    "def get_device_weights(device, bias_dimm, w_dimm):\n",
    "    number_of_floats = w_dimm[0] * w_dimm[1]\n",
    "    weights = np.zeros(w_dimm).reshape(-1)\n",
    "    for i in range(number_of_floats):\n",
    "        device.serial.read()\n",
    "        weights[i] = struct.unpack('f', device.serial.read(4))[0]\n",
    "        \n",
    "    number_of_floats = bias_dimm[0] * bias_dimm[1]\n",
    "    bias = np.zeros(bias_dimm).reshape(-1)\n",
    "    for i in range(number_of_floats):\n",
    "        device.serial.read()\n",
    "        bias[i] = struct.unpack('f', device.serial.read(4))[0]\n",
    "    \n",
    "    return weights.reshape(w_dimm), bias.reshape(bias_dimm)\n",
    "    \n",
    "def get_device_weights_cnn(device, kh, kw, c, kc):\n",
    "    in_size = kh * kw * c\n",
    "    out_size = kh * kw * kc\n",
    "    weights = np.random.randn(kh, kw, c, kc) * np.sqrt(6.0 / (in_size + out_size)).reshape(-1)\n",
    "    for w in weights.reshape(-1):\n",
    "        device.serial.read()\n",
    "        weights[i] = struct.unpack('f', device.serial.read(4))[0]\n",
    "    \n",
    "    bias = np.zeros((1,kc)).reshape(-1)\n",
    "    for b in bias.reshape(-1):\n",
    "        device.serial.read()\n",
    "        bias[i] = struct.unpack('f', device.serial.read(4))[0]\n",
    "\n",
    "    return weights.reshape((kh, kw, c, kc)), bias.reshape((1,kc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "05ef76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_initial_weights(device):\n",
    "    num_layers, layers = receive_model_info(device)\n",
    "    device.metalayers = layers\n",
    "    for layer in layers:\n",
    "        if layer.layer_type == \"Conv2D\":\n",
    "            initialize_device_weights_cnn(device, layer.kh, layer.kw, layer.c, layer.kc)\n",
    "        elif layer.layer_type == \"Dense\":\n",
    "            initialize_device_weights(device, (1,layer.cols), (layer.rows,layer.cols))\n",
    "    print(f\"{device.serial.port} weights initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "2bb19c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_weights(device, weights):\n",
    "    weights = weights[0]\n",
    "    bias = weights[1]\n",
    "    print(f\"Sending bias for Dense {bias.reshape(-1).shape} {device.serial.port}\")\n",
    "    for b in bias.reshape(-1):\n",
    "        data = device.serial.read()\n",
    "        device.serial.write(struct.pack('f', b))\n",
    "    \n",
    "    print(f\"Sending weights for Dense {weights.reshape(-1).shape} {device.serial.port}\")\n",
    "    for w in weights.reshape(-1):\n",
    "        data = device.serial.read()\n",
    "        device.serial.write(struct.pack('f', w))\n",
    "        \n",
    "def send_model_weights(device, weights):\n",
    "    layers = device.metalayers\n",
    "    device.serial.write(b'r')\n",
    "    for i, layer in enumerate(layers):\n",
    "        assert weights[i][0].shape == device.weights[i][0].shape and \\\n",
    "        weights[i][1].shape == device.weights[i][1].shape , \\\n",
    "        f\"{weights[i][0].shape}!={device.weights[i][0].shape}, \\\n",
    "        {weights[i][1].shape}!={device.weights[i][1].shape}\"\n",
    "        \n",
    "        send_weights(device, weights[i])\n",
    "    print(f\"{device.serial.port} weights initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "2e51a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_weights(device):\n",
    "    layers = device.metalayers\n",
    "    device.serial.write(b'g') # Python --> ACK --> Arduino\n",
    "    device.weights = []\n",
    "    for i, layer in enumerate(layers):\n",
    "        print(f\"Doing {i} - {layer}\")\n",
    "        if layer.layer_type == \"Conv2D\":\n",
    "            weights, biases = get_device_weights_cnn(device, layer.kh, layer.kw, layer.c, layer.kc)\n",
    "            device.weights.append((weights, biases))\n",
    "        elif layer.layer_type == \"Dense\":\n",
    "            weights, biases = get_device_weights(device, (1,layer.cols), (layer.rows,layer.cols))\n",
    "            device.weights.append((weights, biases))\n",
    "    print(f\"Model weight received!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "1ab0651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_sample(device, X, y=None):\n",
    "    for s in X.reshape(-1):\n",
    "        data = device.serial.read()\n",
    "        if IS_KEYWORD_SPOTTING:\n",
    "            device.serial.write(struct.pack('h', s))\n",
    "        else:\n",
    "            device.serial.write(struct.pack('f', s))\n",
    "\n",
    "    if y is not None:\n",
    "        for t in y.reshape(-1):\n",
    "            data = device.serial.read()\n",
    "            device.serial.write(struct.pack('f', t))\n",
    "\n",
    "def get_tick():\n",
    "    return round(time.time() * 1000)\n",
    "\n",
    "def train(device, X, y, size=1):\n",
    "    error = 0.0\n",
    "    for i in range(size):\n",
    "        print(f\"Sending element {i}/{size}\")\n",
    "        device.serial.write(b\"t\")\n",
    "        send_sample(device, X[i], y[i].reshape(1,TARGET_SIZE))\n",
    "        start = get_tick()\n",
    "        n_error = device.serial.read(4)\n",
    "        print(f\"returned error = {n_error}\")\n",
    "        end = get_tick()\n",
    "        loss = struct.unpack('f', n_error)[0]\n",
    "        error += loss\n",
    "    return end-start, error/size\n",
    "\n",
    "def predict(device, X):\n",
    "    start = get_tick()\n",
    "    device.serial.write(b\"p\")\n",
    "    send_sample(device, X)\n",
    "    # read last layer size output\n",
    "    output = read_matrix(device, TARGET_SIZE)\n",
    "    return get_tick() - start, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "8a25076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# One hot encoding\n",
    "enc = OneHotEncoder()\n",
    "Y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
    "\n",
    "# Scale data to have mean 0 and variance 1 \n",
    "# which is importance for convergence of the neural network\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data set into training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.5, random_state=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce25415",
   "metadata": {},
   "source": [
    "- call getDevices() to obtain all conected devices\n",
    "- asks the user how many devices you want to use\n",
    "- send the initial model for every device\n",
    "- create thread for every device\n",
    "    - send samples and start training for one epoch\n",
    "- wait for all threads to finish\n",
    "- FEDERATED LEARNING\n",
    "- create thread for every device and receive models\n",
    "- permute the average of every layer\n",
    "- create thread for every device and receive models\n",
    "- send back the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "c367929a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 2\n",
      "Available ports:\n",
      "/dev/cu.wlan-debug - n/a\n",
      "/dev/cu.Bluetooth-Incoming-Port - n/a\n",
      "/dev/cu.usbmodem114101 - Envie M7\n",
      "/dev/cu.usbmodem114201 - Envie M7\n",
      "Port device_1: /dev/cu.usbmodem114101\n",
      "Port device_2: /dev/cu.usbmodem114201\n",
      "Sending blank model for device 0\n",
      "Sending blank model for device 1\n",
      "Sending weights for Dense\n",
      "Sending weights for Dense\n",
      "/dev/cu.usbmodem114201 weights initialized!\n",
      "Sending weights for Dense\n",
      "Sending weights for Dense\n",
      "/dev/cu.usbmodem114101 weights initialized!\n",
      "All devices' weights are initialized!\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "devices = getDevices()\n",
    "\n",
    "number_devices = len(devices)\n",
    "threads = []\n",
    "for i, d in enumerate(devices):\n",
    "    print(f\"Sending blank model for device {i}\")\n",
    "    thread = threading.Thread(target=send_initial_weights, args=(d, ))\n",
    "    thread.daemon = True\n",
    "    threads.append(thread)\n",
    "\n",
    "# Start all the threads\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all the threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"All devices' weights are initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "71bf2a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets start training!!\n",
      "Sending element 0/1Sending element 0/1\n",
      "\n",
      "returned error = b'!\\xc0\\x1c?'\n",
      "Epoch 0/1 took 0 ms, loss = 0.6123066544532776returned error = b'!`\\x97?'\n",
      "Epoch 0/1 took 1 ms, loss = 1.1826211214065552\n",
      "\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "TARGET_SIZE = 3\n",
    "INPUT_SIZE = 4\n",
    "IS_KEYWORD_SPOTTING = False\n",
    "\n",
    "fl_rounds = 4 # number of fl_round\n",
    "epochs = 1 # number of epochs to execute\n",
    "steps = 1 # number of samples to process from the set\n",
    "for r in range(fl_rounds)\n",
    "    threads = []\n",
    "    for device in devices:\n",
    "        thread = threading.Thread(target=train_device, args=(device, X_train, Y_train, epochs, steps))\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "    for thread in threads: thread.join() # Wait for all the threads to end\n",
    "    # do fl\n",
    "    fl(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "684bdd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fl(devices):\n",
    "    # RECEIVE MODELS\n",
    "    print(\"Receiving models from devices...\")\n",
    "    threads = []\n",
    "    for device in devices:\n",
    "        thread = threading.Thread(target=get_model_weights, args=(device,))\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    for thread in threads: thread.join() # Wait for all the threads to end\n",
    "    print(\"Models received\")\n",
    "    # AVERAGE MODELS\n",
    "    num_layers = len(devices[0].weights)\n",
    "    assert num_layers > 0, \"NO LAYERS!\"\n",
    "\n",
    "    list_weights = []\n",
    "    for i in range(0, num_layers):\n",
    "        weights, bias = devices[0].weights[i]\n",
    "        weights = np.zeros_like(weights)\n",
    "        bias = np.zeros_like(bias)\n",
    "        for device in devices:\n",
    "            weights += device.weights[i][0]\n",
    "            bias += device.weights[i][1]\n",
    "        list_weights.append((weights,bias))\n",
    "\n",
    "\n",
    "    for i,(weight,bias) in enumerate(list_weights):\n",
    "        list_weights[i] = (weight / len(devices), bias / len(devices))\n",
    "    print(\"Average performed\")\n",
    "    \n",
    "    # send model\n",
    "    threads = []\n",
    "    for device in devices:\n",
    "        thread = threading.Thread(target=send_model_weights, args=(device, list_weights))\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "    for thread in threads: thread.join() # Wait for all the threads to end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bfa3aa",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f6bacffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending element 0/1\n",
      "Sample sent!\n",
      "returned error = b'\\x8c\\xc5\\x07@'\n",
      "Epoch 0/1 took 1 ms, loss = 2.121432304382324\n"
     ]
    }
   ],
   "source": [
    "def train_device(device, X_train, Y_train, epochs=1, steps = 1):\n",
    "    if not isinstance(X_train, np.ndarray):\n",
    "        X_train = np.array(X_train)\n",
    "    \n",
    "    if not isinstance(Y_train, np.ndarray):\n",
    "        Y_train = np.array(Y_train)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        dt, loss = train(device, np.array(X_train).astype(np.int16), Y_train, steps)\n",
    "        print(f\"Epoch {i}/{epochs} took {dt} ms, loss = {loss}\")\n",
    "IS_KEYWORD_SPOTTING = False\n",
    "train_device(devices[0], X_train, Y_train, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9424317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_device(device, X, steps=1):\n",
    "    if not isinstance(X, numpy.ndarray):\n",
    "        X = np.array(X)\n",
    "        \n",
    "    acc = 0.0\n",
    "    print(f\"Predicting values for {X.shape[0]} elements\")\n",
    "    for i, x in enumerate(X):\n",
    "        dt, res = predict(device, x)\n",
    "        acc += 1 if np.argmax(Y_test[i]) == np.argmax(res) else 0\n",
    "        print(f\"{i}/{X.shape[0]}\")\n",
    "\n",
    "    return acc/X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154086cb",
   "metadata": {},
   "source": [
    "## Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b976396a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e85ffff",
   "metadata": {},
   "source": [
    "### Keyword Spotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8253ded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total available training keywords: 640\n",
      "Total available testing keywords: 80\n",
      "{'blau': 0, 'pedraforca': 1, 'vermell': 2, 'montserrat': 3}\n",
      "{'blau': 0, 'pedraforca': 1, 'vermell': 2, 'montserrat': 3}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "# Keyword samples split\n",
    "samples_folder = \"./datasets/keywords_v3\"\n",
    "train_samples_split = 160 # Number of samples for training of each keyword\n",
    "test_samples_split = 20   # Number of samples for training of each keyword\n",
    "keywords_buttons = {\n",
    "    \"montserrat\": 1,\n",
    "    \"pedraforca\": 2,\n",
    "    \"vermell\": 3,\n",
    "    \"blau\": 4,\n",
    "    #\"verd\": 5,\n",
    "    # \"up\": 1,\n",
    "    # \"backward\": 2,\n",
    "    # \"forward\": 3,\n",
    "    # \"down\": 4,\n",
    "    # \"left\": 3,\n",
    "    # \"right\": 4\n",
    "}\n",
    "def readKeyword(path_dir, keyword):\n",
    "    with open(path_dir) as f:\n",
    "        data = json.load(f)\n",
    "        values = data['payload']['values']\n",
    "        info = keyword.split('/')\n",
    "        return info[0], values\n",
    "import random\n",
    "train_samples_split = 160 # Number of samples for training of each keyword\n",
    "test_samples_split = 20   # Number of samples for training of each keyword\n",
    "\n",
    "# Experiment sizes\n",
    "training_epochs = 160   # Amount of training epochs. Can't be more than kws * train_samples_split\n",
    "testing_epochs = 60     # Amount of test samples of each keyword. Can't be more than kws * test_samples_split\n",
    "\n",
    "# Load the dataset\n",
    "words = list(keywords_buttons.keys())\n",
    "files = []\n",
    "test_files = []\n",
    "for i, word in enumerate(words):\n",
    "    file_list = os.listdir(f\"{samples_folder}/{word}\")\n",
    "    if (len(file_list) < train_samples_split + test_samples_split): \n",
    "        sys.exit(f\"Not enough samples for keyword {word}\")\n",
    "    random.shuffle(file_list)\n",
    "    files.append(list(map(lambda f: f\"{word}/{f}\", file_list[0:train_samples_split])))\n",
    "    test_files.append(list(map(lambda f: f\"{word}/{f}\", file_list[train_samples_split:(train_samples_split+test_samples_split)])))\n",
    "\n",
    "keywords = list(sum(zip(*files), ()))\n",
    "test_keywords = list(sum(zip(*test_files), ()))\n",
    "\n",
    "debug = True\n",
    "if debug: print(f\"Total available training keywords: {len(keywords)}\")\n",
    "if debug: print(f\"Total available testing keywords: {len(test_keywords)}\")\n",
    "    \n",
    "def get_x_y(data):\n",
    "    ys = []\n",
    "    xs = []\n",
    "    train_names = []\n",
    "    for keyword in data:\n",
    "        info = keyword.split('/')\n",
    "        train_names.append(info[0])\n",
    "\n",
    "    train_names = set(train_names)\n",
    "    test_names = []\n",
    "    for keyword in test_keywords:\n",
    "        info = keyword.split('/')\n",
    "        test_names.append(info[0])\n",
    "\n",
    "    test_names = set(test_names)\n",
    "    name_to_int = {x:i for i,x in enumerate(test_names)}\n",
    "    print(name_to_int)\n",
    "    for keyword in data:\n",
    "        name, values = readKeyword(\"./datasets/keywords_v3/\" + keyword, keyword)\n",
    "        ys.append(name_to_int[name])\n",
    "        xs.append(values)\n",
    "    return xs, ys\n",
    "\n",
    "random.shuffle(keywords)\n",
    "random.shuffle(test_keywords)\n",
    "x_train, y_train = get_x_y(keywords)\n",
    "x_test, y_test = get_x_y(test_keywords)\n",
    "\n",
    "X_data = np.array(x_train).astype(np.float32)\n",
    "X_data_test = np.array(x_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e9442b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train, 4)\n",
    "Y_test = np_utils.to_categorical(y_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aafe7c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "#X_normalized = scaler.fit_transform(np.array(x_train))\n",
    "#X_normalized_test = scaler.fit_transform(np.array(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4fa6a2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending element 0/1\n",
      "SAMPLE SENT\n",
      "24 0.002343999920412898\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    dt, loss = train(devices[0], np.array(x_train).astype(np.int16), Y_train, 1)\n",
    "    print(dt, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e620bdd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[173], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m80\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     dt, res \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m Y_test[i] \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(res) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m80.0\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[170], line 33\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(device, X)\u001b[0m\n\u001b[1;32m     31\u001b[0m start \u001b[38;5;241m=\u001b[39m get_tick()\n\u001b[1;32m     32\u001b[0m device\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[43msend_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# read last layer size output\u001b[39;00m\n\u001b[1;32m     35\u001b[0m output \u001b[38;5;241m=\u001b[39m read_matrix(device, dimms[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[170], line 3\u001b[0m, in \u001b[0;36msend_sample\u001b[0;34m(device, X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_sample\u001b[39m(device, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m         device\u001b[38;5;241m.\u001b[39mwrite(struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m, s))\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#print(f\"SAMPLE SENT\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tfg_env/lib/python3.10/site-packages/serial/serialposix.py:565\u001b[0m, in \u001b[0;36mSerial.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(read) \u001b[38;5;241m<\u001b[39m size:\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m         ready, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe_abort_read_r\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipe_abort_read_r \u001b[38;5;129;01min\u001b[39;00m ready:\n\u001b[1;32m    567\u001b[0m             os\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipe_abort_read_r, \u001b[38;5;241m1000\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc = 0.0\n",
    "for i in range(80):\n",
    "    dt, res = predict(devices[0], np.array(x_test)[i])\n",
    "    acc += 1 if Y_test[i] == np.argmax(res) else 0\n",
    "print(f\"Model Accuracy {acc/80.0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc1f98b",
   "metadata": {},
   "source": [
    "### Mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "64663757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000, 10))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "84e780fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.3088966608047485\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    dt, loss = train(devices[0], X_train, Y_train, 1)\n",
    "    print(dt, loss)\n",
    "    \n",
    "acc = 0.0\n",
    "for i in range(797):\n",
    "    dt, res = predict(devices[0], X[1000+i])\n",
    "    acc += 1 if y[1000+i] == np.argmax(res) else 0\n",
    "print(f\"Model Accuracy {acc/797.0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a3de03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X,y = load_digits(return_X_y=True)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_train_one_hot = onehot_encoder.fit_transform(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d102af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "datos = pd.read_csv(\"creditcard.csv\")\n",
    "datos.drop(['Time'], axis=1, inplace=True)\n",
    "datos['Amount'] = StandardScaler().fit_transform(datos['Amount'].values.reshape(-1,1))\n",
    "\n",
    "X_train, X_test = train_test_split(datos, test_size=0.2, random_state=42)\n",
    "X_train = X_train[X_train.Class == 0]\n",
    "X_train = X_train.drop(['Class'], axis=1)\n",
    "X_train = X_train.values\n",
    "\n",
    "Y_test = X_test['Class']\n",
    "X_test = X_test.drop(['Class'], axis=1)\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152ef914",
   "metadata": {},
   "source": [
    "## Anomaly detection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b387d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Type</th>\n",
       "      <th>QR</th>\n",
       "      <th>QS</th>\n",
       "      <th>QRU</th>\n",
       "      <th>QWRP</th>\n",
       "      <th>QWSP</th>\n",
       "      <th>RT</th>\n",
       "      <th>SSS</th>\n",
       "      <th>FMA</th>\n",
       "      <th>packetHeader/Type</th>\n",
       "      <th>packetHeader/Id</th>\n",
       "      <th>packetHeader/Size</th>\n",
       "      <th>packetHeader/Src</th>\n",
       "      <th>packetHeader/Dst</th>\n",
       "      <th>packetHeader/Via</th>\n",
       "      <th>packetHeader/SeqId</th>\n",
       "      <th>packetHeader/Num</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>120132</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>56988</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>120252</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>56988</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>120156</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>56988</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>112604</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>35872</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>119964</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>35872</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Type  QR  QS  QRU  QWRP  QWSP  RT  SSS     FMA  packetHeader/Type  \\\n",
       "0   0     0   0   0    0     0     0   1   11  120132                  4   \n",
       "1   0     0   0   0    0     0     0   0   12  120252                  4   \n",
       "2   0     0   0   0    0     0     0   1   12  120156                  4   \n",
       "3   0     0   0   0    0     0     0   1   17  112604                  4   \n",
       "4   1     0   0   0    0     0     0   2   18  119964                  4   \n",
       "\n",
       "   packetHeader/Id  packetHeader/Size  packetHeader/Src  packetHeader/Dst  \\\n",
       "0                0                  8             56988             65535   \n",
       "1                0                  8             56988             65535   \n",
       "2                0                  8             56988             65535   \n",
       "3                0                  8             35872             65535   \n",
       "4                0                  8             35872             65535   \n",
       "\n",
       "   packetHeader/Via  packetHeader/SeqId  packetHeader/Num    src  \n",
       "0                 0                   0                 0  25516  \n",
       "1                 0                   0                 0  27980  \n",
       "2                 0                   0                 0  35872  \n",
       "3                 0                   0                 0  56988  \n",
       "4                 0                   0                 0  25516  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"monitorData.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794c9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2dfa1",
   "metadata": {},
   "source": [
    "Is important to normalize data for faster converge and better performance during training.\n",
    "the range of the input values is important due to the activation function used in our models, these functions are sensitive to the input values. When values are big the gradient of activation functions may become 0 or unstable depending on the activation function used. Normalizing the input values help preventing this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77202faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the dataset\n",
    "normalized_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38f4bf25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Type</th>\n",
       "      <th>QR</th>\n",
       "      <th>QS</th>\n",
       "      <th>QRU</th>\n",
       "      <th>QWRP</th>\n",
       "      <th>QWSP</th>\n",
       "      <th>RT</th>\n",
       "      <th>SSS</th>\n",
       "      <th>FMA</th>\n",
       "      <th>packetHeader/Type</th>\n",
       "      <th>packetHeader/Id</th>\n",
       "      <th>packetHeader/Size</th>\n",
       "      <th>packetHeader/Src</th>\n",
       "      <th>packetHeader/Dst</th>\n",
       "      <th>packetHeader/Via</th>\n",
       "      <th>packetHeader/SeqId</th>\n",
       "      <th>packetHeader/Num</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843617</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.847739</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.844441</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.006704</td>\n",
       "      <td>0.584994</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.629466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.837845</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.629466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  Type   QR   QS  QRU  QWRP  QWSP        RT       SSS       FMA  \\\n",
       "0  0.000000   0.0  0.0  0.0  0.0   0.0   0.0  0.333333  0.000000  0.843617   \n",
       "1  0.000000   0.0  0.0  0.0  0.0   0.0   0.0  0.000000  0.001117  0.847739   \n",
       "2  0.000000   0.0  0.0  0.0  0.0   0.0   0.0  0.333333  0.001117  0.844441   \n",
       "3  0.000000   0.0  0.0  0.0  0.0   0.0   0.0  0.333333  0.006704  0.584994   \n",
       "4  0.011236   0.0  0.0  0.0  0.0   0.0   0.0  0.666667  0.007821  0.837845   \n",
       "\n",
       "   packetHeader/Type  packetHeader/Id  packetHeader/Size  packetHeader/Src  \\\n",
       "0           0.048193              0.0           0.275862          1.000000   \n",
       "1           0.048193              0.0           0.275862          1.000000   \n",
       "2           0.048193              0.0           0.275862          1.000000   \n",
       "3           0.048193              0.0           0.275862          0.629466   \n",
       "4           0.048193              0.0           0.275862          0.629466   \n",
       "\n",
       "   packetHeader/Dst  packetHeader/Via  packetHeader/SeqId  packetHeader/Num  \\\n",
       "0               1.0               0.0                 0.0               0.0   \n",
       "1               1.0               0.0                 0.0               0.0   \n",
       "2               1.0               0.0                 0.0               0.0   \n",
       "3               1.0               0.0                 0.0               0.0   \n",
       "4               1.0               0.0                 0.0               0.0   \n",
       "\n",
       "        src  \n",
       "0  0.000000  \n",
       "1  0.078292  \n",
       "2  0.329054  \n",
       "3  1.000000  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc91c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
